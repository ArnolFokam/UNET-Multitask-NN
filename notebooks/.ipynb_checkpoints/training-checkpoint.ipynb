{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1138b27",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\desktop\\coms4059a - research project\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\dell\\desktop\\coms4059a - research project\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.gk7gx5keq4f6uyo3p26ulgbqyhgqo7j4.gfortran-win_amd64.dll\n",
      "c:\\users\\dell\\desktop\\coms4059a - research project\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from configparser import ConfigParser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models.pnsamp_2d import PNSAMP_2D\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils.directory import check_or_create\n",
    "from utils.data_generators import DicomDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1c7e0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05d41c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ConfigParser()\n",
    "parser.read('../project.conf')\n",
    "\n",
    "# Get Directory setting\n",
    "# add '../' since you are in the a notebook\n",
    "saved_weights_path = check_or_create('../' + parser.get('train', 'SAVED_WEIGHTS_PATH'))\n",
    "checkpoints_path = check_or_create('../' + parser.get('train', 'CHECKPOINTS_PATH'))\n",
    "history_path = check_or_create('../' + parser.get('train', 'HISTORY_PATH'))\n",
    "data_path = check_or_create('../' + parser.get('train', 'DATA_PATH'))\n",
    "batch_size = int(parser.get('train', 'BATCH_SIZE'))\n",
    "image_size = int(parser.get('train', 'IMAGE_SIZE'))\n",
    "variant = parser.get('train', 'VARIANT')\n",
    "epochs = int(parser.get('train', 'EPOCHS'))\n",
    "test_ratio = float(parser.get('train', 'TEST_RATIO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1abcf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>nodule_no</th>\n",
       "      <th>slice_no</th>\n",
       "      <th>original_image</th>\n",
       "      <th>mask_image</th>\n",
       "      <th>subtlety</th>\n",
       "      <th>internalStructure</th>\n",
       "      <th>calcification</th>\n",
       "      <th>sphericity</th>\n",
       "      <th>margin</th>\n",
       "      <th>lobulation</th>\n",
       "      <th>spiculation</th>\n",
       "      <th>texture</th>\n",
       "      <th>malignancy</th>\n",
       "      <th>is_cancer</th>\n",
       "      <th>is_clean</th>\n",
       "      <th>img_path</th>\n",
       "      <th>mask_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>0001_NI000_slice000</td>\n",
       "      <td>0001_MA000_slice000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.././data/processed\\image\\LIDC-IDRI-0001\\0001_...</td>\n",
       "      <td>.././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001</td>\n",
       "      <td>0</td>\n",
       "      <td>001</td>\n",
       "      <td>0001_NI000_slice001</td>\n",
       "      <td>0001_MA000_slice001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.././data/processed\\image\\LIDC-IDRI-0001\\0001_...</td>\n",
       "      <td>.././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001</td>\n",
       "      <td>0</td>\n",
       "      <td>002</td>\n",
       "      <td>0001_NI000_slice002</td>\n",
       "      <td>0001_MA000_slice002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.././data/processed\\image\\LIDC-IDRI-0001\\0001_...</td>\n",
       "      <td>.././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001</td>\n",
       "      <td>0</td>\n",
       "      <td>003</td>\n",
       "      <td>0001_NI000_slice003</td>\n",
       "      <td>0001_MA000_slice003</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.././data/processed\\image\\LIDC-IDRI-0001\\0001_...</td>\n",
       "      <td>.././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001</td>\n",
       "      <td>0</td>\n",
       "      <td>004</td>\n",
       "      <td>0001_NI000_slice004</td>\n",
       "      <td>0001_MA000_slice004</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.././data/processed\\image\\LIDC-IDRI-0001\\0001_...</td>\n",
       "      <td>.././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id nodule_no slice_no       original_image           mask_image  \\\n",
       "0       0001         0      000  0001_NI000_slice000  0001_MA000_slice000   \n",
       "1       0001         0      001  0001_NI000_slice001  0001_MA000_slice001   \n",
       "2       0001         0      002  0001_NI000_slice002  0001_MA000_slice002   \n",
       "3       0001         0      003  0001_NI000_slice003  0001_MA000_slice003   \n",
       "4       0001         0      004  0001_NI000_slice004  0001_MA000_slice004   \n",
       "\n",
       "   subtlety  internalStructure  calcification  sphericity  margin  lobulation  \\\n",
       "0       5.0                1.0            6.0         4.0     4.0         3.0   \n",
       "1       5.0                1.0            6.0         4.0     4.0         3.0   \n",
       "2       5.0                1.0            6.0         4.0     4.0         3.0   \n",
       "3       5.0                1.0            6.0         4.0     4.0         3.0   \n",
       "4       5.0                1.0            6.0         4.0     4.0         3.0   \n",
       "\n",
       "   spiculation  texture  malignancy is_cancer  is_clean  \\\n",
       "0          5.0      5.0           5      True     False   \n",
       "1          5.0      5.0           5      True     False   \n",
       "2          5.0      5.0           5      True     False   \n",
       "3          5.0      5.0           5      True     False   \n",
       "4          5.0      5.0           5      True     False   \n",
       "\n",
       "                                            img_path  \\\n",
       "0  .././data/processed\\image\\LIDC-IDRI-0001\\0001_...   \n",
       "1  .././data/processed\\image\\LIDC-IDRI-0001\\0001_...   \n",
       "2  .././data/processed\\image\\LIDC-IDRI-0001\\0001_...   \n",
       "3  .././data/processed\\image\\LIDC-IDRI-0001\\0001_...   \n",
       "4  .././data/processed\\image\\LIDC-IDRI-0001\\0001_...   \n",
       "\n",
       "                                           mask_path  \n",
       "0  .././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...  \n",
       "1  .././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...  \n",
       "2  .././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...  \n",
       "3  .././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...  \n",
       "4  .././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, 'meta/meta_info.csv'),\n",
    "                         dtype={'patient_id': str,\n",
    "                                'nodule_no': str,\n",
    "                                'slice_no': str})\n",
    "\n",
    "# use only non-clean scans (scans that contains at least one nodule) for training\n",
    "df = df[df['is_clean'] == False]\n",
    "\n",
    "def get_paths(x):\n",
    "    patient_img_path = os.path.join(data_path, 'image', 'LIDC-IDRI-' + x[0])\n",
    "    patient_mask_path = os.path.join(data_path, 'mask', 'LIDC-IDRI-' + x[0])\n",
    "    return [os.path.join(patient_img_path, x[1] + '.npy'), os.path.join(patient_mask_path, x[2] + '.npy')]\n",
    "\n",
    "temp = df[['patient_id',\n",
    "                'original_image',\n",
    "                'mask_image']].values\n",
    "\n",
    "paths = list(map(get_paths, temp))\n",
    "df_paths = pd.DataFrame(paths, columns=['img_path', 'mask_path'])\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_paths.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df = pd.concat([df, df_paths], axis=1, sort=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "546353a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>nodule_no</th>\n",
       "      <th>slice_no</th>\n",
       "      <th>original_image</th>\n",
       "      <th>mask_image</th>\n",
       "      <th>subtlety</th>\n",
       "      <th>internalStructure</th>\n",
       "      <th>calcification</th>\n",
       "      <th>sphericity</th>\n",
       "      <th>margin</th>\n",
       "      <th>lobulation</th>\n",
       "      <th>spiculation</th>\n",
       "      <th>texture</th>\n",
       "      <th>malignancy</th>\n",
       "      <th>is_cancer</th>\n",
       "      <th>is_clean</th>\n",
       "      <th>img_path</th>\n",
       "      <th>mask_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001</td>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>0001_NI000_slice000</td>\n",
       "      <td>0001_MA000_slice000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.././data/processed\\image\\LIDC-IDRI-0001\\0001_...</td>\n",
       "      <td>.././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001</td>\n",
       "      <td>0</td>\n",
       "      <td>001</td>\n",
       "      <td>0001_NI000_slice001</td>\n",
       "      <td>0001_MA000_slice001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.././data/processed\\image\\LIDC-IDRI-0001\\0001_...</td>\n",
       "      <td>.././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001</td>\n",
       "      <td>0</td>\n",
       "      <td>002</td>\n",
       "      <td>0001_NI000_slice002</td>\n",
       "      <td>0001_MA000_slice002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.././data/processed\\image\\LIDC-IDRI-0001\\0001_...</td>\n",
       "      <td>.././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001</td>\n",
       "      <td>0</td>\n",
       "      <td>003</td>\n",
       "      <td>0001_NI000_slice003</td>\n",
       "      <td>0001_MA000_slice003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.././data/processed\\image\\LIDC-IDRI-0001\\0001_...</td>\n",
       "      <td>.././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001</td>\n",
       "      <td>0</td>\n",
       "      <td>004</td>\n",
       "      <td>0001_NI000_slice004</td>\n",
       "      <td>0001_MA000_slice004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>.././data/processed\\image\\LIDC-IDRI-0001\\0001_...</td>\n",
       "      <td>.././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id nodule_no slice_no       original_image           mask_image  \\\n",
       "0       0001         0      000  0001_NI000_slice000  0001_MA000_slice000   \n",
       "1       0001         0      001  0001_NI000_slice001  0001_MA000_slice001   \n",
       "2       0001         0      002  0001_NI000_slice002  0001_MA000_slice002   \n",
       "3       0001         0      003  0001_NI000_slice003  0001_MA000_slice003   \n",
       "4       0001         0      004  0001_NI000_slice004  0001_MA000_slice004   \n",
       "\n",
       "   subtlety  internalStructure  calcification  sphericity  margin  lobulation  \\\n",
       "0       1.0                1.0            6.0         4.0    0.75         0.5   \n",
       "1       1.0                1.0            6.0         4.0    0.75         0.5   \n",
       "2       1.0                1.0            6.0         4.0    0.75         0.5   \n",
       "3       1.0                1.0            6.0         4.0    0.75         0.5   \n",
       "4       1.0                1.0            6.0         4.0    0.75         0.5   \n",
       "\n",
       "   spiculation  texture  malignancy is_cancer  is_clean  \\\n",
       "0          5.0      1.0           5      True     False   \n",
       "1          5.0      1.0           5      True     False   \n",
       "2          5.0      1.0           5      True     False   \n",
       "3          5.0      1.0           5      True     False   \n",
       "4          5.0      1.0           5      True     False   \n",
       "\n",
       "                                            img_path  \\\n",
       "0  .././data/processed\\image\\LIDC-IDRI-0001\\0001_...   \n",
       "1  .././data/processed\\image\\LIDC-IDRI-0001\\0001_...   \n",
       "2  .././data/processed\\image\\LIDC-IDRI-0001\\0001_...   \n",
       "3  .././data/processed\\image\\LIDC-IDRI-0001\\0001_...   \n",
       "4  .././data/processed\\image\\LIDC-IDRI-0001\\0001_...   \n",
       "\n",
       "                                           mask_path  \n",
       "0  .././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...  \n",
       "1  .././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...  \n",
       "2  .././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...  \n",
       "3  .././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...  \n",
       "4  .././data/processed\\mask\\LIDC-IDRI-0001\\0001_M...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['subtlety',\n",
    "            'margin',\n",
    "            'lobulation',\n",
    "            'texture',]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df[features] = MinMaxScaler().fit_transform(df[features])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35cfbe6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|=============BUILDING GENERATOR=============|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_batches = int(len(df) / batch_size)\n",
    "\n",
    "print(\"|=============BUILDING GENERATOR=============|\\n\")\n",
    "datagen = DicomDataGenerator(df,\n",
    "                                     img_path_col_name='img_path',\n",
    "                                     mask_path_col_name='mask_path',\n",
    "                                     features_cols=features,\n",
    "                                     batch_size=batch_size,\n",
    "                                     target_size=(image_size, image_size, 1)\n",
    "                                     )\n",
    "\n",
    "traingen, valigen = train_test_split(datagen, test_size=test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b413bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 2)    18          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 2)    8           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 2)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 16, 16, 2)    0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 4)    72          max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 4)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 4)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 8, 8)      288         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 8, 8)      32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 8, 8, 8)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 8)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 16)     1152        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4, 4, 16)     64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4, 4, 16)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 16)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 2, 2, 1024)   147456      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2, 2, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 2, 2, 1024)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 1024)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 1, 1, 128)    1179776     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 2, 2, 128)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2, 2, 1152)   0           up_sampling2d[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 2, 2, 1024)   10616832    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2, 2, 1024)   4096        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2, 2, 1024)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 4, 4, 1024)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 4, 1040)   0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 4, 16)     149760      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 4, 4, 16)     64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 4, 4, 16)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 16)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 24)     0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 8)      1728        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 8)      32          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 8)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 8)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 12)   0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 4)    432         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 4)    16          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 4)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 4)    0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 6)    0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 2)    108         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 2)    8           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 2)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "segmentation (Conv2D)           (None, 32, 32, 1)    3           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 1)    0           segmentation[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 128)          0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_regression (Dense)        (None, 4)            260         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 5)            325         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,131,346\n",
      "Trainable params: 12,127,130\n",
      "Non-trainable params: 4,216\n",
      "__________________________________________________________________________________________________\n",
      "Note: Starting training from scratch.\n"
     ]
    }
   ],
   "source": [
    "model = PNSAMP_2D(num_attributes=len(features), input_size=(image_size, image_size, 1), variant=variant)\n",
    "model.summary()\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Instantiate a loss function.\n",
    "loss_fn1 = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn2 = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn3 = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# setup training checkpoints\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=model)\n",
    "manager = tf.train.CheckpointManager(\n",
    "            checkpoint,\n",
    "            os.path.join(checkpoints_path, variant),\n",
    "            max_to_keep=3\n",
    "        )\n",
    "\n",
    "checkpoint.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(\"Note: Starting training with model restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Note: Starting training from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eadc49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|==================TRAINING==================|\n",
      "\n",
      "\n",
      "Start of epoch 0\n",
      "0.8631417 0.66438603 2.02115\n",
      "0.86044157 0.69840515 0.701831\n",
      "0.85928386 0.675588 1.6967638\n",
      "0.8785541 0.66880345 0.66723365\n",
      "0.6931472 0.88364434 0.7879296\n",
      "0.81876856 0.7413798 1.744837\n",
      "0.8614342 0.6713829 2.0072348\n",
      "0.8654052 0.66753644 2.2963648\n",
      "0.8522401 0.7172903 2.0158873\n",
      "0.8564257 0.8353897 2.3365335\n",
      "0.85227984 0.76731646 2.0664635\n",
      "0.6931472 0.7766371 1.6486651\n",
      "0.84425557 0.73038 2.0445495\n",
      "0.85284036 0.7272352 1.7351965\n",
      "0.8447528 0.82485044 1.9869735\n",
      "0.86473143 0.64347935 1.9990085\n",
      "0.6931472 0.66023153 1.701957\n",
      "0.802246 0.89437306 0.63516885\n",
      "0.6931472 0.75714374 1.701957\n",
      "0.85874426 0.760123 0.67298394\n",
      "0.86491084 0.71848834 0.6428019\n",
      "0.8583615 0.8330553 2.0655267\n",
      "0.6931472 0.77890956 0.7879296\n",
      "0.86676407 0.65791595 2.625307\n",
      "0.8328591 0.78330684 2.303465\n",
      "0.8805627 0.5997789 2.640932\n",
      "0.84621215 0.75277305 2.3194244\n",
      "0.8323426 0.72338426 0.6597336\n",
      "0.8565939 0.7234318 1.7029974\n",
      "0.8623212 0.7841083 1.7425201\n",
      "0.6931472 0.6996477 1.6486651\n",
      "0.8496926 0.73507893 2.0503392\n",
      "0.6931472 0.6996477 1.6486651\n",
      "0.86593217 0.8246319 2.3074892\n",
      "0.85502374 0.774389 2.3508923\n",
      "0.86107886 0.7290932 2.2876518\n",
      "0.87117046 0.9723479 1.7481008\n",
      "0.8578803 0.65872574 1.9960172\n",
      "0.803253 0.6812664 0.63516885\n",
      "0.864965 0.77381516 2.3578506\n",
      "0.8210088 0.6284305 1.7138278\n",
      "0.83633614 0.81827676 2.0168\n",
      "0.8678109 0.7627029 1.6945331\n",
      "0.8653257 0.6692375 1.6921556\n",
      "0.8558029 0.73749375 2.0436504\n",
      "0.879863 0.7076372 1.9400406\n",
      "0.86180264 0.77334344 2.0402646\n",
      "0.6931472 0.77890956 0.7879296\n",
      "0.85548764 0.6958085 2.2718456\n",
      "0.6931472 0.6996477 1.6486651\n",
      "0.6931472 0.66023153 1.701957\n",
      "0.6931472 0.72141355 1.701957\n",
      "0.6931472 0.7766371 1.6486651\n",
      "0.86052203 0.6939988 1.6874421\n",
      "0.8256811 0.7628654 1.7348814\n",
      "0.85643107 0.7386217 0.67092985\n",
      "0.8459519 0.783367 2.2739773\n",
      "0.8431401 0.7079996 2.0366955\n",
      "0.871351 0.7470517 0.66665715\n",
      "0.85131216 0.7732403 2.25797\n",
      "0.8643255 0.7562963 0.65456176\n",
      "0.86724627 0.7671696 2.2934656\n",
      "0.8618352 0.8484757 1.7136929\n",
      "0.8554054 0.797354 2.2710292\n",
      "0.8452865 0.78835714 2.309106\n",
      "0.8629952 0.7733719 2.3701835\n",
      "0.86775136 0.75495195 2.2845156\n",
      "0.84526175 0.7387013 2.0673664\n",
      "0.83410287 0.7399605 2.0311875\n",
      "0.8428409 0.89503753 2.3001878\n",
      "0.8297064 0.79347026 2.3362877\n",
      "0.826044 0.7438871 2.0017657\n",
      "0.8808445 0.74370754 1.7287093\n",
      "0.6931472 0.7372209 0.7879296\n",
      "0.8452295 0.7263236 1.7388625\n",
      "0.85582894 0.6821048 2.3514485\n",
      "0.8805462 0.7383617 1.7196305\n",
      "0.8686463 0.6777228 2.302226\n",
      "0.864209 0.7746651 1.9983492\n",
      "0.8588016 0.8069206 1.9367127\n",
      "0.85044247 0.6525401 2.010772\n",
      "0.86136246 0.6645757 2.6336281\n",
      "0.83751774 0.88714284 1.7213087\n",
      "0.85868096 0.76571685 1.7529399\n",
      "0.8691777 0.7292216 2.3091056\n",
      "0.8506867 0.7797536 2.3070421\n",
      "0.6931472 0.95053864 0.7879296\n",
      "0.8513884 0.6968689 1.7449907\n",
      "0.85198736 0.7245559 2.2950435\n",
      "0.83766353 0.73462075 2.0281227\n",
      "0.85516286 0.8388295 2.2913983\n",
      "0.8573175 0.7718482 2.3460622\n",
      "0.8813898 0.73369193 2.006897\n",
      "0.8522944 0.7520728 1.7023199\n",
      "0.8648584 0.8134612 2.296284\n",
      "0.6931472 0.7589867 1.701957\n",
      "0.8630469 0.6560431 0.68000644\n",
      "0.82914484 0.80075395 2.0410194\n",
      "0.83055764 0.8218373 1.7051413\n",
      "0.8767983 0.64787847 0.65507513\n",
      "0.6931472 0.88364434 0.7879296\n",
      "0.8644566 0.7239957 0.65027964\n",
      "0.6931472 0.76082975 1.6486651\n",
      "0.8401432 0.70293355 2.653471\n",
      "0.8651101 0.7013673 2.3017545\n",
      "0.8559389 0.6833397 2.674286\n",
      "0.8431466 0.7031606 0.66589403\n",
      "0.84351504 0.7437678 1.7224796\n",
      "0.8635765 0.7286931 2.031454\n",
      "0.83593595 0.7191025 1.7141018\n",
      "0.8553175 0.75832057 1.7184167\n",
      "0.6931472 0.7372209 1.6486651\n",
      "0.84284604 0.6274533 2.6011236\n",
      "0.8469103 0.7070289 2.633665\n",
      "0.842664 0.7075825 1.7133839\n",
      "0.8618833 0.6705593 2.6428416\n",
      "0.6931472 0.75714374 1.701957\n",
      "0.8673456 0.7507237 1.7042214\n",
      "0.86422807 0.80650586 2.0026312\n",
      "0.8413646 0.78072584 2.3052273\n",
      "0.86759794 0.6549102 2.0118587\n",
      "0.83800924 0.8310295 2.0283117\n",
      "0.8548574 0.7618155 2.3178482\n",
      "0.8560883 0.6592839 2.2822592\n",
      "0.8626102 0.76217955 2.2449167\n",
      "0.6931472 0.75714374 2.249389\n",
      "0.87730235 0.72563994 1.7056491\n",
      "0.6931472 0.7390639 0.7879296\n",
      "0.8832556 0.7357061 2.0311985\n",
      "0.6931472 0.72141355 1.701957\n",
      "0.8440169 0.6738391 1.7390218\n",
      "0.85116637 0.69312066 1.7236364\n",
      "0.8440368 0.73837286 2.0616274\n",
      "0.86099625 0.7627372 2.2408504\n",
      "0.86346066 0.7791327 2.3387332\n",
      "0.86783683 0.73678035 0.66149616\n",
      "0.8530091 0.7418338 2.3122468\n",
      "0.83966756 0.80458355 2.0058072\n",
      "0.8536395 0.8325189 1.7258434\n",
      "0.8552019 0.7966029 2.3150907\n",
      "0.6931472 0.66023153 1.701957\n",
      "0.8679674 0.666388 2.2887719\n",
      "0.84093446 0.80588996 2.2992358\n",
      "0.6931472 0.66023153 1.701957\n",
      "0.85005474 0.69330025 2.6571748\n",
      "0.8095821 0.65560305 1.7334915\n",
      "0.859411 0.919491 1.7074018\n",
      "0.6931472 0.7372209 1.701957\n",
      "0.86873615 0.65642834 2.6629658\n",
      "0.6931472 0.7589867 1.701957\n",
      "0.8631017 0.69072294 2.3725235\n",
      "0.8737142 0.80717176 2.0314395\n",
      "0.8596209 0.69130397 2.348866\n",
      "0.85338414 0.8188507 2.3137827\n",
      "0.6931472 0.75714374 2.249389\n",
      "0.86094123 0.8046818 2.3681922\n",
      "0.8443608 0.68736196 1.7111495\n",
      "0.85964674 0.7374638 1.7087241\n",
      "0.86693764 0.77339274 0.6712711\n",
      "0.83824205 0.8733118 1.9772878\n",
      "0.84995824 0.7114972 2.640905\n",
      "0.82123554 0.8846024 1.7357069\n",
      "0.852705 0.79578483 2.296863\n",
      "0.8546472 0.86792856 2.2770107\n",
      "0.6931472 0.66023153 1.701957\n",
      "0.6931472 0.77890956 0.7879296\n",
      "0.8522987 0.68285096 1.7294017\n",
      "0.6931472 0.6978047 2.249389\n",
      "0.8715177 0.71287227 1.7272599\n",
      "0.85444045 0.7486298 1.7179993\n",
      "0.6931472 0.8423958 1.6486651\n",
      "0.858657 0.6963674 2.3071532\n",
      "0.87071276 0.75789475 0.665807\n",
      "0.8486683 0.75657296 2.3340497\n",
      "0.84665745 0.80871755 2.3005643\n",
      "0.843037 0.91332126 2.0503697\n",
      "0.8521871 0.80888486 2.051004\n",
      "0.8436779 0.7850101 0.6477889\n",
      "0.85945463 0.691017 1.7038136\n",
      "0.85105944 0.78089577 2.3058548\n",
      "0.8501005 0.7417054 2.3401465\n",
      "0.8446695 0.7214907 2.050042\n",
      "0.85335195 0.67115164 1.9837761\n",
      "0.84622884 0.79116833 2.3576639\n",
      "0.858235 0.98724794 1.7228987\n",
      "0.8365873 0.7631294 2.3517425\n",
      "0.8657324 0.6694913 2.0223382\n",
      "0.85386336 0.69849414 2.0480165\n",
      "0.8156889 0.7063773 1.6993687\n",
      "0.8474485 0.67497724 1.9688177\n",
      "0.8524217 0.8081244 2.3345032\n",
      "0.8627758 0.80707383 2.3114245\n",
      "0.8589766 0.67926294 2.2950785\n",
      "0.85845673 0.8694409 2.273174\n",
      "0.8448827 0.7657368 1.7133732\n",
      "0.8763708 0.73960674 2.035365\n",
      "0.8383996 0.7977163 2.0304058\n",
      "0.6931472 0.9610843 1.6486651\n",
      "0.85183793 0.7131204 2.3150845\n",
      "0.86122614 0.7019575 1.707959\n",
      "0.8540075 0.8310329 1.6912904\n",
      "0.83052075 0.8122344 1.9873879\n",
      "0.6931472 0.6978047 2.249389\n",
      "0.8643854 0.7840215 2.28085\n",
      "0.8506233 0.7509541 2.331175\n",
      "0.864818 0.7561071 2.0567281\n",
      "0.8554166 0.66392934 2.694083\n",
      "0.84461874 0.6880988 2.0671334\n",
      "0.85827684 0.73055124 1.6962273\n",
      "0.87227774 0.63292253 2.6537728\n",
      "0.87454116 0.7352766 1.691839\n",
      "0.85019934 0.7780366 2.316371\n",
      "0.82742286 0.9080651 1.7066545\n",
      "0.83595204 0.7182441 2.040656\n",
      "0.86992687 0.7691446 2.3517685\n",
      "0.869454 0.72251946 2.0461345\n",
      "0.8680848 0.92897666 1.7077541\n",
      "0.86280704 0.7404304 2.30439\n",
      "0.8610002 0.7856941 2.31353\n",
      "0.83326334 0.80107653 2.3092015\n",
      "0.8553022 0.71488005 1.9911468\n",
      "0.8579784 0.7229433 2.3230753\n",
      "0.8441501 0.6736479 2.6202629\n",
      "0.83304775 0.7697918 1.991565\n",
      "0.6931472 0.66023153 1.701957\n",
      "0.8454999 0.76440656 2.2741177\n",
      "0.855595 0.7663691 2.0041664\n",
      "0.87221384 0.74145466 2.0025277\n",
      "0.6931472 0.8893566 1.6486651\n",
      "0.86785895 0.6990781 2.3511255\n",
      "0.8626195 0.8121665 2.274839\n",
      "0.8632375 0.7703413 2.298263\n",
      "0.8903896 0.775023 1.7250968\n",
      "0.844442 0.75089824 2.2717671\n",
      "0.87168854 0.73375946 1.9981265\n",
      "0.6931472 0.7372209 0.7879296\n",
      "0.86634636 0.7854253 2.3031313\n",
      "0.84959805 1.0064359 1.7255999\n",
      "0.8498616 0.67773247 2.307189\n",
      "0.79158825 0.8751471 2.0442355\n",
      "0.86676407 0.7647781 2.0513878\n",
      "0.8605079 0.7734657 2.326418\n",
      "0.87079614 0.8846139 0.66208154\n",
      "0.86226773 0.7635381 1.725214\n",
      "0.6931472 0.72141355 1.701957\n",
      "0.8462249 0.8617399 2.350667\n",
      "0.8441937 0.88673985 2.2931962\n",
      "0.8314502 0.7913085 2.3270695\n",
      "0.86917937 0.68205434 2.2621284\n",
      "0.8514519 0.7155142 1.7289817\n",
      "0.6931472 0.75714374 1.701957\n",
      "0.8689069 0.730307 2.0012403\n",
      "0.6931472 0.76082975 1.6486651\n",
      "0.84139884 0.8069749 2.3400996\n",
      "0.8504307 0.80889916 2.0276837\n",
      "0.84783113 0.672759 0.6390508\n",
      "0.8524822 0.8031105 2.0504954\n",
      "0.8537462 0.732532 2.2738833\n",
      "0.85592425 0.8536937 2.3355236\n",
      "0.8404684 0.76155084 2.3451955\n",
      "0.8254713 0.6804581 1.9720042\n",
      "0.8470321 0.71604943 1.7061663\n",
      "0.6931472 0.7372209 1.6486651\n",
      "0.8297653 0.6929085 0.66675687\n",
      "0.87402475 0.82354355 2.0059445\n",
      "0.86247885 0.67601407 1.9523032\n",
      "0.8735028 0.8556731 1.7669672\n",
      "0.86593395 0.7160679 1.7281911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8736132 0.89555156 1.7005198\n",
      "0.8586614 0.77723885 2.304624\n",
      "0.86922014 0.80802375 2.335538\n",
      "0.6931472 0.6978047 2.249389\n",
      "0.85499734 0.68542564 2.3603902\n",
      "0.8760941 0.74958676 0.6294673\n",
      "0.8659718 0.6776309 1.7498779\n",
      "0.8654699 0.79187965 2.2965488\n",
      "0.83579135 0.7896466 2.0035658\n",
      "0.85472757 0.73495597 2.3146386\n",
      "0.86117244 0.75975823 2.3161056\n",
      "0.8474271 0.62004054 2.6527412\n",
      "0.8719537 0.8074862 2.392201\n",
      "0.85051614 0.7147863 2.338967\n",
      "0.8330889 0.74498004 1.9937263\n",
      "0.8449485 0.6902333 0.66948444\n",
      "0.6931472 0.75714374 1.6486651\n",
      "0.86164355 0.8337464 2.2900681\n",
      "0.8448905 0.7019567 2.0573766\n",
      "0.8595584 0.88743424 1.7080607\n",
      "0.8695783 0.70566404 2.0309196\n",
      "0.856676 0.78009856 2.3218699\n",
      "0.6931472 0.75714374 2.249389\n",
      "0.85988796 0.74958366 2.060814\n",
      "0.870672 0.8643998 1.6801468\n",
      "0.85702145 0.7026162 0.66573864\n",
      "0.86198765 0.7691536 2.3257985\n",
      "0.85786587 0.7276551 1.9921687\n",
      "0.6931472 0.7372209 1.701957\n",
      "0.85078484 0.79536885 2.3298664\n",
      "0.83543074 0.86279976 0.6570469\n",
      "0.87120014 0.7392744 2.268171\n",
      "0.8687494 0.68561107 1.7189226\n",
      "0.8493396 0.6819124 1.7179688\n",
      "0.8548093 0.7139529 2.0450234\n",
      "0.84106755 0.7270949 1.9951388\n",
      "0.8618926 0.7765006 1.711627\n",
      "0.86130106 0.6935103 2.6060345\n",
      "0.86287487 0.8007079 1.7280792\n",
      "0.8551115 0.6250197 2.0251446\n",
      "0.8610629 0.72471106 0.6716014\n",
      "0.86112547 0.6645964 1.7479551\n",
      "0.8491039 0.950998 1.7063596\n",
      "0.85340726 0.80862 2.0089178\n",
      "0.85666955 0.6378247 2.6088295\n",
      "0.84533864 0.82143736 1.7211376\n",
      "0.8582869 0.63694 2.636674\n",
      "0.8580215 0.8541436 2.296092\n",
      "0.84944856 0.7009274 2.284842\n",
      "0.8580646 0.7117611 2.6511154\n",
      "0.8681341 0.7335076 0.65845174\n",
      "0.8605414 0.6771752 1.7261703\n",
      "0.6931472 0.7390639 0.7879296\n",
      "0.8621524 0.64771146 1.9924204\n",
      "0.8623029 0.7391007 1.6756239\n",
      "0.8673788 0.76095766 2.318894\n",
      "0.6931472 0.8423958 1.6486651\n",
      "0.8574143 0.7213304 2.3099473\n",
      "0.87130076 0.7374037 2.2472067\n",
      "0.6931472 0.7390639 1.6486651\n",
      "0.8705194 0.68815905 1.7481008\n",
      "0.8753464 0.80567163 2.2525845\n",
      "0.8301124 0.73398906 1.985508\n",
      "0.85395557 0.8170277 2.3034356\n",
      "0.85501546 0.76383007 2.3363612\n",
      "0.87738085 0.8231709 2.0254927\n",
      "0.84489167 0.7908199 2.2748246\n",
      "0.8641636 0.64958084 2.3212845\n",
      "0.8692384 0.7293329 1.7181485\n",
      "0.6931472 0.75714374 1.701957\n",
      "0.8594059 0.72576064 2.3655577\n",
      "0.8645358 0.7255295 1.6985044\n",
      "0.87580705 0.6956025 2.0213273\n",
      "0.87038666 0.64271814 1.7262503\n",
      "0.8516239 0.80885804 2.0085983\n",
      "0.8586186 0.679775 2.3053205\n",
      "0.8634239 0.8359337 2.306164\n",
      "0.86136246 0.77024996 2.069394\n",
      "0.8685323 0.70261437 1.7027767\n",
      "0.87399507 0.7803818 1.7070453\n",
      "0.8701116 0.6729933 1.9949371\n",
      "0.85697865 0.78445685 2.3315892\n",
      "0.6931472 0.72141355 1.701957\n",
      "0.8582105 0.7856567 2.3305857\n",
      "0.8626554 0.73320436 1.7264023\n",
      "0.8725667 0.74336207 1.9791803\n",
      "0.864508 0.6599171 1.6695085\n",
      "0.85688674 0.70211697 1.7305151\n",
      "0.83289015 0.68797547 1.7327328\n",
      "0.8212916 0.7878782 1.9889009\n",
      "0.8604224 0.658083 0.6761773\n",
      "0.8664187 0.7524793 1.7104956\n",
      "0.85833323 0.69086844 1.6948841\n",
      "0.86618465 0.76702416 1.733294\n",
      "0.868245 0.727373 1.7155069\n",
      "0.8720882 0.68417954 1.697905\n",
      "0.6931472 0.75714374 1.701957\n",
      "0.86629295 0.6988747 0.67048705\n",
      "0.84492934 0.7589586 2.3263001\n",
      "0.8582565 0.65859765 2.3225923\n",
      "0.86942995 0.72520727 0.64652246\n",
      "0.6931472 0.6996477 1.6486651\n",
      "0.85014737 0.74298084 2.3013456\n",
      "0.8525543 0.68414307 0.6652164\n",
      "0.83740175 0.7700705 2.2995813\n",
      "0.85638285 0.74866706 2.3672006\n",
      "0.85160863 0.7419649 2.2863157\n",
      "0.8504295 0.8055062 1.9814379\n",
      "0.8438817 0.67722553 1.7279637\n",
      "0.6931472 0.7390639 1.6486651\n",
      "0.8460848 0.77858937 2.2884345\n",
      "0.8545807 0.9173391 2.3842106\n",
      "0.8460529 0.85474104 2.327479\n",
      "0.8626072 0.9690846 0.65021026\n",
      "0.6931472 0.80024594 1.6486651\n",
      "0.87510663 0.6804637 1.6737686\n",
      "0.82723224 0.7516161 2.0235047\n",
      "0.85575247 0.6728356 1.7284297\n",
      "0.85397255 0.7852802 2.2945285\n",
      "0.8557592 0.6723553 2.307426\n",
      "0.81352603 0.7061641 1.693023\n",
      "0.8622112 0.7585108 2.3550072\n",
      "0.85826194 0.85202986 1.963186\n",
      "0.86075896 0.71106315 2.3180215\n",
      "0.6931472 0.75714374 1.701957\n",
      "0.8585629 0.6959646 2.0719793\n",
      "0.8233873 0.74978346 2.3008835\n",
      "0.86403733 0.7949928 2.0388527\n",
      "0.8763152 0.8185081 1.7471703\n",
      "0.86682475 0.76068205 1.9924623\n",
      "0.86287487 0.723778 1.7280792\n",
      "0.8599879 0.80462694 2.3161032\n",
      "0.8395855 0.741927 2.0531168\n",
      "0.84753466 0.73231417 2.3229578\n",
      "0.86690205 0.7006421 2.365262\n",
      "0.8414136 0.79584664 2.2814925\n",
      "0.87296724 0.79273444 2.2827344\n",
      "0.8481906 0.67363846 1.6956422\n",
      "0.858369 0.70113504 0.65240604\n",
      "0.8483271 0.7990148 1.9852797\n",
      "0.86379755 0.95789695 1.6978512\n",
      "0.84977466 0.6665047 2.0287137\n",
      "0.6931472 0.9610843 1.6486651\n",
      "0.6931472 0.66023153 1.701957\n",
      "0.8646575 0.77282804 2.3176107\n",
      "0.85927147 0.89545083 0.6778664\n",
      "0.85482436 0.77814853 2.3244662\n",
      "0.8326141 0.8123991 2.3232737\n",
      "0.8679006 0.6816596 2.3507044\n",
      "0.86525506 0.6437298 2.6374152\n",
      "0.8580047 0.7854246 2.328288\n",
      "0.6931472 0.9610843 1.6486651\n",
      "0.85289574 0.79836845 2.2841766\n",
      "0.86603296 0.9186312 0.6758031\n",
      "0.8638663 0.8393669 1.7071607\n",
      "0.86717993 0.66859066 1.7135067\n",
      "0.6931472 0.75714374 1.701957\n",
      "0.86411536 0.7598344 0.6759239\n",
      "0.86975324 0.8020183 2.310577\n",
      "0.84173375 0.8051309 2.2869651\n",
      "0.6931472 0.8423958 1.6486651\n",
      "0.8525661 0.762277 2.0066705\n",
      "0.8517957 0.81690997 2.3487551\n",
      "0.84988296 0.7444574 2.2592251\n",
      "0.8661815 0.8265023 2.0298662\n",
      "0.8639324 0.754499 1.7115486\n",
      "0.8660974 0.7132277 2.363194\n",
      "0.8575499 0.7729153 2.2753282\n",
      "0.6931472 0.6978047 2.249389\n",
      "0.8448929 0.7221546 1.730175\n",
      "0.6931472 0.7372209 1.701957\n",
      "0.6931472 0.75714374 1.701957\n",
      "0.85346884 0.6940522 0.7074707\n",
      "0.8463367 0.7950175 2.2926402\n",
      "0.85934025 0.77949715 2.3105354\n",
      "0.837638 0.8534734 0.6447489\n",
      "0.6931472 0.6996477 1.6486651\n",
      "0.860926 0.73830616 2.3531456\n",
      "0.8593114 0.7779411 1.718898\n",
      "0.6931472 0.7390639 0.7879296\n",
      "0.8571807 0.74163055 0.67650664\n",
      "0.86938107 0.85168344 2.3500001\n",
      "0.85633224 0.82533395 2.0040853\n",
      "0.8614614 0.66755044 1.9641765\n",
      "0.8517438 0.7991868 2.2747927\n",
      "0.8555043 0.77590716 2.0043223\n",
      "0.8464901 0.7887511 2.0106766\n",
      "0.85995525 0.82258445 2.0651317\n",
      "0.8430278 0.7892968 2.2817178\n",
      "0.80994654 0.6757662 1.9980109\n",
      "0.8690294 0.66434586 1.6991204\n",
      "0.87140244 0.7220767 2.0150726\n",
      "0.8687269 0.64212126 2.3143425\n",
      "0.8550907 0.78406394 1.720696\n",
      "0.8642235 0.7240935 1.9847846\n",
      "0.8607405 0.71164274 0.6802286\n",
      "0.6931472 0.75714374 1.701957\n",
      "0.8601521 0.6866118 1.7122637\n",
      "0.8380094 0.73560447 2.0011044\n",
      "0.81306374 0.6498635 1.727057\n",
      "0.8700707 0.72545636 2.377218\n",
      "0.85283214 0.7578466 2.327858\n",
      "0.8493186 0.60943156 2.320094\n",
      "0.8476631 0.79993945 2.2954319\n",
      "0.85577047 0.7996545 1.728746\n",
      "0.84829855 0.64779943 2.056122\n",
      "0.8548204 0.6323005 2.357965\n",
      "0.836341 0.80665386 2.3053126\n",
      "0.84729713 0.8062731 1.9782258\n",
      "0.8628217 0.6704503 2.661114\n",
      "0.8663218 0.7570667 1.7240509\n",
      "0.6931472 0.72141355 1.6486651\n",
      "0.803253 0.709193 1.7324193\n",
      "0.86375517 0.86345303 2.6098216\n",
      "0.8546223 0.7683337 1.7351856\n",
      "0.8731115 0.78667754 2.2285554\n",
      "0.8563396 0.7254586 2.2965837\n",
      "0.8671949 0.67836624 2.01421\n",
      "0.838953 0.8174464 2.0341086\n",
      "0.8568507 0.7282836 2.0394652\n",
      "0.8776813 0.80392694 2.0199912\n",
      "0.86380374 0.6700339 1.7065614\n",
      "0.8633717 0.78745085 2.2690568\n",
      "0.863725 0.72520155 1.6995225\n",
      "0.8346714 0.8151034 1.9904612\n",
      "0.6931472 0.85959554 1.6486651\n",
      "0.86157674 0.77753794 2.3471045\n",
      "0.6931472 0.7390639 0.7879296\n",
      "0.6931472 0.72141355 1.6486651\n",
      "0.6931472 0.8893566 1.6486651\n",
      "0.8676381 0.7813592 2.2720003\n",
      "0.8588504 0.67151076 0.6472003\n",
      "0.86812776 0.79663813 2.2734766\n",
      "0.8374314 0.89916146 1.7411461\n",
      "0.8654094 0.67916894 1.9583579\n",
      "0.6931472 0.75714374 1.701957\n",
      "0.8583899 0.6550398 2.6623333\n",
      "0.6931472 0.66023153 1.701957\n",
      "0.8610931 0.7489424 2.6230822\n",
      "0.84080327 0.7765364 2.322902\n",
      "0.8467168 0.92815465 2.3653936\n",
      "0.8744464 0.94144464 0.6744492\n",
      "0.86243045 0.6622944 0.67472875\n",
      "0.847851 0.7536335 2.336203\n",
      "0.86309713 0.7028766 1.9872664\n",
      "0.850218 0.66675603 1.6956298\n",
      "0.8543197 0.66168797 2.0229747\n",
      "0.86774015 0.69132864 1.6963959\n",
      "0.8106823 0.7356888 1.7237025\n",
      "0.861752 0.79162866 1.9765904\n",
      "0.85129994 0.6743954 0.6507647\n",
      "0.8622296 0.6991561 2.3746176\n",
      "0.8560108 0.6982502 2.0185747\n",
      "0.8550962 0.78494024 2.3339314\n",
      "0.81995267 0.74696356 1.9863548\n",
      "0.8668775 0.7841413 1.6824726\n",
      "0.83945805 0.75731474 2.0101614\n",
      "0.85632676 0.6340239 2.024798\n",
      "0.8494942 0.8662993 2.3386223\n",
      "0.8675235 0.8177883 1.7077587\n",
      "0.8589245 0.72957045 0.6900639\n",
      "0.8528527 0.7557951 2.3665018\n",
      "0.87856555 0.68900895 2.343741\n",
      "0.84666413 0.6713184 2.320209\n",
      "0.8584393 0.6997122 0.6719024\n",
      "0.8757857 0.6916733 1.7150089\n",
      "0.8765699 0.7104846 1.7456341\n",
      "0.8731293 0.80727255 0.6873528\n",
      "0.8658682 0.8163656 2.3349679\n",
      "0.86129475 0.7772007 0.6694343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86075467 0.69485307 0.6764477\n",
      "0.8465644 0.76011086 2.3768713\n",
      "0.86484027 0.7482414 2.2874095\n",
      "0.86657774 0.75257504 1.6785628\n",
      "0.85496104 0.769808 0.64566827\n",
      "0.8493025 0.6712617 1.7005812\n",
      "0.8652837 0.77346325 2.3213077\n",
      "0.8613577 0.70001096 1.9935642\n",
      "0.84682286 0.7166847 1.7282305\n",
      "0.6931472 0.6978047 2.249389\n",
      "0.85466397 0.80195016 1.7192734\n",
      "0.6931472 0.6996477 1.6486651\n",
      "0.8542906 0.790282 1.715948\n",
      "0.86192536 0.7356515 0.6397994\n",
      "0.8629722 0.7654318 2.320546\n",
      "0.6931472 0.6996477 1.6486651\n",
      "0.8484613 0.79236597 2.2755392\n",
      "0.8486793 0.8137698 0.6501631\n",
      "0.8709553 0.96542346 1.6905702\n",
      "0.83798784 0.7973753 2.0125108\n",
      "0.8530734 0.90567946 1.7041711\n",
      "0.853752 0.76031363 2.336894\n",
      "0.6931472 0.7589867 1.6486651\n",
      "0.8710947 0.79998755 1.9788386\n",
      "0.83714557 0.73861337 2.3269973\n",
      "0.8485563 0.82650435 0.64666355\n",
      "0.8698245 0.73255736 2.0268233\n",
      "0.8607555 0.99675095 1.7199788\n",
      "0.8772834 0.6267064 2.651363\n",
      "0.8386243 0.8802246 1.979897\n",
      "0.85996 0.7885628 2.385758\n",
      "0.86331946 0.73781824 1.7026873\n",
      "0.85375386 0.89527726 2.0570855\n",
      "0.8507606 0.8229084 0.6515702\n",
      "0.6931472 0.66023153 1.701957\n",
      "0.85309416 0.67652655 2.6778536\n",
      "0.86333 0.8454802 2.3370614\n",
      "0.8546815 0.6792409 1.7461468\n",
      "0.86275256 0.8465471 1.7023757\n",
      "0.8685283 0.6444706 1.7182543\n",
      "0.8446907 0.78087825 2.3483617\n",
      "0.85689175 0.7934245 1.9796987\n",
      "0.8693174 0.80581725 1.7418487\n",
      "0.6931472 0.6978047 2.249389\n",
      "0.8620666 0.8225702 2.2599077\n",
      "0.86683315 0.8014611 0.6676833\n",
      "0.6931472 0.6996477 1.6486651\n",
      "0.8683382 0.690827 2.0234222\n",
      "0.86411124 0.8130109 2.300725\n",
      "0.8630528 0.73819464 0.6977685\n",
      "0.8581099 0.6572661 2.028559\n",
      "0.8505834 0.86999893 1.7150023\n",
      "0.852725 0.74226266 1.7266096\n",
      "0.85391384 0.8565988 2.2997842\n",
      "0.8648797 0.8569757 2.3119752\n",
      "0.6931472 0.76082975 0.7879296\n",
      "0.8378788 0.6283319 2.3191628\n",
      "0.8557012 0.69987357 1.7319889\n",
      "0.8586909 0.7217736 2.2757807\n",
      "0.8487276 0.76849455 2.228876\n",
      "0.85650504 0.70420057 0.6669771\n",
      "0.86669046 0.70994234 0.6654528\n",
      "0.8559283 0.6849202 1.7202657\n",
      "0.84885335 0.8105828 2.0655675\n",
      "0.8694684 0.6621578 0.659858\n",
      "0.86217195 0.77923703 2.3296626\n",
      "0.8515774 0.7496126 2.2428732\n",
      "0.87742484 0.7420125 2.0158513\n",
      "0.836295 0.708279 2.328271\n",
      "0.85328305 0.7132424 2.045714\n",
      "0.853727 0.66458887 2.6308117\n",
      "0.8399254 0.7832688 2.3351948\n",
      "0.8732132 0.7068459 1.7118719\n",
      "0.8515378 0.75357246 0.6554614\n",
      "0.8598023 0.76573205 1.7054502\n",
      "0.83236164 0.74716353 1.99773\n",
      "0.8512152 0.98808515 0.6663929\n",
      "0.86502934 0.69117504 1.698899\n",
      "0.8682012 0.89004946 2.0424662\n",
      "0.8612219 0.75756407 1.6831017\n",
      "0.8549324 0.7077081 2.3016195\n",
      "0.8723691 0.86700064 2.6060514\n",
      "0.8513229 0.68949974 1.9955071\n",
      "0.6931472 0.75714374 2.249389\n",
      "0.8490034 0.8113797 1.9973829\n",
      "0.6931472 0.6996477 1.6486651\n",
      "0.8474107 0.6428535 2.0294251\n",
      "0.8747517 0.77191514 2.0388024\n",
      "0.87110007 0.9867348 1.7342595\n",
      "0.8586675 0.92993575 1.7243261\n",
      "0.848959 0.81218326 1.7222648\n",
      "0.8667069 0.73678035 1.7324073\n",
      "0.85151803 0.79583323 1.7286978\n",
      "0.85866714 0.76088214 2.292713\n",
      "0.8664297 0.8369698 0.65865713\n",
      "0.86248654 0.736879 2.265433\n",
      "0.8683269 0.6175316 2.333789\n",
      "0.85250133 0.76070285 1.7263656\n",
      "0.882723 0.7288684 1.7127299\n",
      "0.8714214 0.8781493 1.7302048\n",
      "0.6931472 0.85959554 1.6486651\n",
      "0.84488314 0.74895453 2.3013225\n",
      "0.8676972 0.72082394 1.9734366\n",
      "0.84562355 0.8300193 2.2967741\n",
      "0.84845996 0.6720823 0.64573133\n",
      "0.84780407 0.7126487 1.7463801\n",
      "0.86138505 0.82331055 2.28061\n",
      "0.855957 0.69594 2.6251273\n",
      "0.8400997 0.7457515 2.3233895\n",
      "0.8606852 0.86276144 2.3065672\n",
      "0.85900855 0.75071985 1.6907153\n",
      "0.8443618 0.8089919 2.3201666\n",
      "0.8653027 0.7817282 2.093323\n",
      "0.8615421 0.88093615 0.6708319\n",
      "0.86879206 0.6621172 2.3042786\n",
      "0.8453881 0.81437135 2.042295\n",
      "0.86556154 0.6521306 2.6339347\n",
      "0.8579344 0.80749106 0.64893603\n",
      "0.8593782 0.69064325 0.6700046\n",
      "0.83731264 0.73272014 2.3264084\n",
      "0.86474645 0.69545555 1.7229414\n",
      "0.6931472 0.75714374 2.249389\n",
      "0.6931472 0.7390639 1.6486651\n",
      "0.8733625 0.78459 1.7379258\n",
      "0.8633157 0.68861085 1.7142068\n",
      "0.8903896 0.6982675 0.6560271\n",
      "0.8575558 0.6966617 2.5905602\n",
      "0.79794914 0.6624049 2.0244699\n",
      "0.86225724 0.7836804 0.65016484\n",
      "0.87731683 0.6973317 2.0061176\n",
      "0.8474345 0.80668175 2.322298\n",
      "0.865884 0.7278229 1.716913\n",
      "0.6931472 0.66023153 1.701957\n",
      "0.86114013 0.7019575 0.67107654\n",
      "0.83500963 0.8914212 1.7166107\n",
      "0.85923374 0.7401891 2.5889277\n",
      "0.8678434 0.75198996 1.9851034\n",
      "0.855842 0.8198462 2.017381\n",
      "0.8695304 0.8181492 2.3337915\n",
      "0.8645982 0.6940055 1.7119644\n",
      "0.868417 0.7491757 1.6947293\n",
      "0.6931472 0.72141355 1.6486651\n",
      "0.882723 0.8580414 1.7127299\n",
      "0.875746 0.7482309 1.9953215\n",
      "0.86675227 0.62924397 2.6288204\n",
      "0.85866797 0.7149767 1.6918623\n",
      "0.6931472 0.77890956 0.7879296\n",
      "0.85352105 0.70443356 2.0585885\n",
      "0.8515775 0.719182 0.6576817\n",
      "0.8558295 0.6804613 1.9795558\n",
      "0.8361207 0.71189487 1.7391977\n",
      "0.8479239 0.72567624 1.7482965\n",
      "0.84240687 0.72904587 2.2723198\n",
      "0.8560653 0.8086934 1.7179993\n",
      "0.6931472 0.6978047 2.249389\n",
      "0.8649632 0.6244239 0.65817183\n",
      "0.857746 0.77619207 2.2928102\n",
      "0.8377558 0.6996446 1.711102\n",
      "0.6931472 0.66023153 1.701957\n",
      "0.849971 0.68404585 0.66227865\n",
      "0.86164355 0.72825426 1.7410338\n",
      "0.8519852 0.69238293 1.9927793\n",
      "0.83716726 0.75302213 1.9966348\n",
      "0.8649162 0.69165313 2.3438897\n",
      "0.84370697 0.7655394 2.24548\n",
      "0.85104525 0.6872052 1.737437\n",
      "0.6931472 0.6996477 1.6486651\n",
      "0.8510568 0.789194 2.2672896\n",
      "0.8580419 0.82307255 2.0414224\n",
      "0.6931472 0.75714374 1.701957\n",
      "0.87640613 0.71180546 1.7068181\n",
      "0.85267866 0.69640934 1.728777\n",
      "0.6931472 0.6996477 1.6486651\n",
      "0.8440625 0.64389515 2.6883152\n",
      "0.8613403 1.0024879 1.6907063\n",
      "0.83719563 0.67225266 1.9770279\n",
      "0.8488108 0.76917833 2.3249526\n",
      "0.8650075 0.7975076 0.666\n",
      "0.8388563 0.7609002 2.296418\n",
      "0.87586856 0.7942599 1.7378151\n",
      "0.86205184 0.6463893 1.7278359\n",
      "0.83694106 0.777876 2.3316295\n",
      "0.87471443 0.6934881 1.7240541\n",
      "0.8551476 0.77631485 2.0673318\n",
      "0.8616549 0.6695577 1.7168993\n",
      "0.8335054 0.73949826 2.0723815\n",
      "0.85680115 0.66624933 1.9771817\n",
      "0.8633417 0.67681 0.64159185\n",
      "0.8556263 0.747795 2.2958355\n",
      "0.79962707 0.85779965 1.9869759\n",
      "0.8700258 0.81228507 2.3254337\n",
      "0.85064405 0.7584841 2.3561447\n",
      "0.85242367 0.73215806 1.7291873\n",
      "0.6931472 0.7372209 1.6486651\n",
      "0.8582672 0.76909935 2.2899642\n",
      "0.8577614 0.66173625 2.6189804\n",
      "0.86214983 0.7475511 2.3508983\n",
      "0.8583109 0.71859455 2.3439422\n",
      "0.8616364 0.8279482 1.7258089\n",
      "0.8583899 0.6904656 0.646748\n",
      "0.8616018 0.6910381 2.2908444\n",
      "0.8676809 0.7130567 1.7315099\n",
      "0.8573434 0.6919942 0.6518191\n",
      "0.85849756 0.7143486 1.7308861\n",
      "0.84793025 0.8535732 1.7251037\n",
      "0.8591344 0.8217392 2.3667426\n",
      "0.8656512 0.7993337 1.7117515\n",
      "0.813955 0.70684856 1.689398\n",
      "0.83961797 0.7938682 2.2764595\n",
      "0.8538946 0.6890857 2.3224287\n",
      "0.8394857 0.7841347 2.2754235\n",
      "0.84865785 0.75489086 2.3303955\n",
      "0.8399059 0.7490638 0.62527835\n",
      "0.8555541 0.87853706 1.7258434\n",
      "0.84596723 0.8597396 2.2870975\n",
      "0.8504514 0.9107169 2.3260717\n",
      "0.8716725 0.8364738 1.7141998\n",
      "0.8333499 0.7869847 2.307264\n",
      "0.8350101 0.80585104 2.3303118\n",
      "0.6931472 0.7589867 1.6486651\n",
      "0.8580179 0.6409751 2.289735\n",
      "0.8574236 0.66170734 0.645418\n",
      "0.8672961 0.74686277 1.6710756\n",
      "0.8411923 0.7040916 1.7371107\n",
      "0.8509945 0.8828043 2.297409\n",
      "0.6931472 0.8423958 1.6486651\n",
      "0.8626756 0.7967361 2.297253\n",
      "0.8612851 0.7954483 2.3049095\n",
      "0.8570888 0.667976 2.0113912\n",
      "0.85630244 0.6789611 2.6337628\n",
      "0.854743 1.0263673 1.7242548\n",
      "0.8508666 0.68176085 1.9800985\n",
      "0.84488475 0.79661345 2.032882\n",
      "0.8184637 0.84968066 1.9965649\n",
      "0.83412045 0.7881223 2.3071864\n",
      "0.8440859 0.74232316 2.28408\n",
      "0.8645434 0.7427054 2.348878\n",
      "0.6931472 0.8893566 1.6486651\n",
      "0.8353346 0.7754586 2.2765698\n",
      "0.8695843 0.7896808 1.7405231\n",
      "0.86058706 0.65326333 2.6345088\n",
      "0.85380745 0.6747729 2.0725565\n",
      "0.86919945 0.6632542 0.6582409\n",
      "0.85799086 0.759161 1.9682164\n",
      "0.86688614 0.79393274 0.6408741\n",
      "0.8614689 0.9059574 2.2721403\n",
      "0.8518212 0.63793486 0.64335793\n",
      "0.8648037 0.7635493 2.3098452\n",
      "0.85822606 0.9397836 1.7072227\n",
      "0.84540784 0.69291234 1.9638697\n",
      "0.86636025 0.7036729 1.6896532\n",
      "0.85874426 0.70404017 0.67298394\n",
      "0.85441196 0.8514161 2.0455317\n",
      "0.8557782 0.6755614 2.2854903\n",
      "0.84951854 0.7982832 1.9857261\n",
      "0.8476627 0.6818273 1.7247119\n",
      "0.8724382 0.6190388 2.6382985\n",
      "0.8540057 0.7109714 2.2818916\n",
      "0.86043733 0.8014215 2.3198652\n",
      "0.832949 0.752473 2.0348692\n",
      "0.8602103 0.68912673 1.7259611\n",
      "0.8509423 0.6841798 1.9623024\n",
      "0.85792166 0.7898375 2.3544028\n",
      "0.87166715 0.6967249 1.7126231\n",
      "0.8326061 0.6731322 1.7001915\n",
      "0.8290209 0.74598455 1.733336\n",
      "0.8247305 0.7572603 2.330004\n",
      "0.8491913 0.8081821 0.6378378\n",
      "0.8601799 0.74921715 2.0306869\n",
      "0.8578335 0.6472044 1.7348232\n",
      "0.8568823 0.6404073 2.6462028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8419472 0.7632591 2.313263\n",
      "0.8762628 0.83673286 2.3027675\n",
      "0.85950446 0.7255377 0.65215564\n",
      "0.8447868 0.6295689 0.63283026\n",
      "0.8673456 0.7675092 1.7042214\n",
      "0.860469 0.771387 2.36427\n",
      "0.6931472 0.7390639 0.7879296\n",
      "0.85469365 0.63230467 2.2908535\n",
      "0.8678082 0.73123634 1.7205392\n",
      "0.8559026 0.8391847 2.017067\n",
      "0.87392354 0.6793578 0.63964206\n",
      "0.8410033 0.73874336 2.0500672\n",
      "0.86568165 0.8005887 1.9821975\n",
      "0.8749988 0.7481543 1.702806\n",
      "0.8697804 0.712931 1.7356513\n",
      "0.83918625 0.7555946 2.0402985\n",
      "0.860559 0.7259947 1.7393818\n",
      "0.86366856 0.74623275 1.7169391\n",
      "0.85896206 0.82086575 0.64676154\n",
      "0.8825528 0.94605935 2.273182\n",
      "0.8506607 0.65624404 0.65532076\n",
      "0.86241347 0.6853442 1.7026873\n",
      "0.85190964 0.67493284 2.5964618\n",
      "0.8487168 0.84854984 0.63706845\n",
      "0.83812934 0.80995536 2.030328\n",
      "0.8490378 0.94828963 1.7474228\n",
      "0.6931472 0.6996477 0.7879296\n",
      "0.8676732 0.7133495 1.7106105\n",
      "0.6931472 0.75714374 2.249389\n",
      "0.8441677 0.6584096 2.6480112\n",
      "0.8362238 0.7666728 2.3465993\n",
      "0.86513686 0.88768065 0.6571364\n",
      "0.86056644 0.6689584 2.0098262\n",
      "0.85306466 0.6099018 2.3467488\n",
      "0.8602096 0.7348844 0.65628237\n",
      "0.842585 0.60661995 2.3020577\n",
      "0.8731293 0.81786966 1.6832833\n",
      "0.8686846 0.6203178 2.6202483\n",
      "0.83752066 0.8072877 2.315374\n",
      "0.6931472 0.72141355 1.701957\n",
      "0.8405779 0.7023489 1.7145827\n",
      "0.6931472 0.7589867 1.6486651\n",
      "0.8747322 0.8387165 0.6736303\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22972/3880129763.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# Run the forward pass of the layer. The operations that the layer applies to its inputs are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;31m# going to be recorded on the GradientTape. segmentation_logits, multi_regr_logits, class_logits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0msegmentation_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_regr_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[1;31m# Logits for this minibatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\desktop\\coms4059a - research project\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\desktop\\coms4059a - research project\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m--> 420\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    421\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\desktop\\coms4059a - research project\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\desktop\\coms4059a - research project\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\desktop\\coms4059a - research project\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1240\u001b[0m             self.kernel, ids, weights, combiner='sum')\n\u001b[0;32m   1241\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMatMul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m     \u001b[1;31m# Broadcast kernel to inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\desktop\\coms4059a - research project\\venv\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m           \u001b[1;34m'Please pass these args as kwargs instead.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m           .format(f=f.__name__, kwargs=f_argspec.args))\n\u001b[1;32m--> 404\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorator_argspec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_argspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\desktop\\coms4059a - research project\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5692\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5693\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5694\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   5695\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5696\u001b[0m         transpose_b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# record of training\n",
    "history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'training_time': [],\n",
    "        }\n",
    "\n",
    "# the validation will be use save a\n",
    "# checkpoint of the model for the\n",
    "# best loss\n",
    "best_validation_loss = np.inf\n",
    "\n",
    "print(\"|==================TRAINING==================|\\n\")\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    total_loss1 = 0.0\n",
    "    total_loss2 = 0.0\n",
    "    total_loss3 = 0.0\n",
    "    start_train_time = time.time()\n",
    "    i = 0\n",
    "    # Iterate over the batches of the train dataset.\n",
    "    for _, (x_batch_train, mask_batch_train, feats_batch_train, mal_batch_train) in enumerate(traingen):\n",
    "        i += 1\n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables auto-differentiation.\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # Run the forward pass of the layer. The operations that the layer applies to its inputs are\n",
    "            # going to be recorded on the GradientTape. segmentation_logits, multi_regr_logits, class_logits\n",
    "            segmentation_logits, multi_regr_logits, class_logits = model(x_batch_train, training=True)  #\n",
    "            # Logits for this minibatch\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "            # Compute the loss value for this mini batch.\n",
    "            loss_value1 = loss_fn1(mask_batch_train, segmentation_logits)\n",
    "            loss_value2 = loss_fn2(feats_batch_train, multi_regr_logits)\n",
    "            loss_value3 = loss_fn3(mal_batch_train, class_logits)\n",
    "            print(loss_value1.numpy(), loss_value2.numpy(), loss_value3.numpy())\n",
    "            \n",
    "            # add different losses to total loss\n",
    "            total_loss1 += loss_value1.numpy()\n",
    "            total_loss2 += loss_value1.numpy()\n",
    "            total_loss3 += loss_value1.numpy()\n",
    "\n",
    "    \"\"\"MULTI-CLASSIFICATOIN\"\"\"\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss.\n",
    "    # grads = tape.gradient([loss_value1, loss_value2, loss_value3], model.trainable_weights)\n",
    "    grads = tape.gradient(loss_value1, model.trainable_weights)\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    end_train_time = time.time()\n",
    "    history['train_loss'].append(total_loss1 / i)\n",
    "    history['training_time'].append(end_train_time - start_train_time)\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    total_loss1 = 0.0\n",
    "    total_loss2 = 0.0\n",
    "    total_loss3 = 0.0\n",
    "    start_train_time = time.time()\n",
    "    i = 0\n",
    "    for _, (x_batch_val, mask_batch_val, feats_batch_val, mal_batch_val) in enumerate(valigen):\n",
    "        i += 1\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            segmentation_logits, multi_regr_logits, class_logits = model(x_batch_val, training=True)\n",
    "\n",
    "            # Compute the loss value for this mini batch.\n",
    "            loss_value1 = loss_fn1(mask_batch_val, segmentation_logits)\n",
    "            loss_value2 = loss_fn2(feats_batch_val, multi_regr_logits)\n",
    "            loss_value3 = loss_fn3(mal_batch_val, class_logits)\n",
    "            print(loss_value1.numpy(), loss_value2.numpy(), loss_value3.numpy())\n",
    "\n",
    "        # add different losses to total loss\n",
    "        total_loss1 += loss_value1.numpy()\n",
    "        total_loss2 += loss_value1.numpy()\n",
    "        total_loss3 += loss_value1.numpy()\n",
    "\n",
    "    history['val_loss'].append(total_loss1 / i)\n",
    "\n",
    "    # save model if performance is better (loss is lower)\n",
    "    if history['val_loss'][-1] < best_validation_loss:\n",
    "        save_path = manager.save()\n",
    "        print(\"Saved checkpoint for step {}: {}, loss {:1.3f}\".format(int(checkpoint.step),\n",
    "                                                                              save_path,\n",
    "                                                                              history['val_loss'][-1]))\n",
    "        model.save_weights(os.path.join(saved_weights_path, variant), save_format='tf')\n",
    "        checkpoint.step.assign_add(1)\n",
    "        best_validation_loss = history['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61aa099d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22972/2974210357.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Final training loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Final validation loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# save history file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtoday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print('Final training loss', history['train_loss'][-1])\n",
    "print('Final validation loss', history['val_loss'][-1])\n",
    "\n",
    "# save history file\n",
    "today = datetime.datetime.now()\n",
    "\n",
    "if today.hour < 12:\n",
    "    h = \"00\"\n",
    "else:\n",
    "    h = \"12\"\n",
    "    \n",
    "file_path = check_or_create(os.path.join(history_path, variant))\n",
    "\n",
    "with open(os.path.join(file_path, 'history_{}.json'.format(today.strftime('%Y%m%d') + h +\n",
    "                                                                                 str(today.minute))),'w') as fp:\n",
    "    json.dump(history, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049d2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
